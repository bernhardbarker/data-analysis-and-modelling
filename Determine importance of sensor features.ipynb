{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a2189e",
   "metadata": {},
   "source": [
    "This is an exercise to determine the importance of sensor features given a labelled dataset.\n",
    "\n",
    "### Result\n",
    "\n",
    "The final ranking I got for the importance of the sensors was: 6, 8, 4, 0, 2, 3, 9, 5, 7, 1. One can predict the label using only sensor 6 with very high accuracy (above 95%). There was only a few percent difference between some sensors - sensor 0 and 2 specifically had roughly the same predictive power of about 80%. Sensors 1, 7 and 5 had percentages in the low to mid 50’s, which is little more than random in terms of predictive power.\n",
    "\n",
    "### Method\n",
    "\n",
    "I trained a Support Vector Machine (SVM) for each individual feature and ranked the features according to the quality of the models.\n",
    "\n",
    "As is standard with this approach, I split the data into a training set to train on and a test set to evaluate the quality of the model. Since the dataset is small, it makes sense to have a fairly large test set and I also chose an equal number of positive and negative samples for each set. If a set is too small or it has much more positive or negative samples than the overall dataset (which is more likely with smaller sets), it may not be representative. If the test set isn't representative, the score on the test set wouldn't be useful.\n",
    "\n",
    "I used an approach similar to k-fold cross-validation to reduce the variability of the ranking. I trained and evaluated multiple models using different subsets as the test set, and then averaged the scores each model got on its test set to get the final score. I looked at the standard deviation of the scores to get a more detailed understanding of the results and ensure there weren’t outliers. I used k=4 (4-fold cross-validation) to give a fairly large test set.\n",
    "\n",
    "### Advantages and disadvantages of this approach\n",
    "\n",
    "The overall approach is reasonably fast, although not as fast as some others. The number of models required is linear in the number of features, although the complexity of each model is low, given that it’s only dependent on one feature. How long each of those models take to train would be dependent on the number of samples. It strikes a good balance between performance and solution quality.\n",
    "\n",
    "SVMs work fairly well on small datasets, don’t take particularly long to train and captures somewhat complex relationships between the feature and the label.\n",
    "\n",
    "It does not evaluate how predictive combinations of features might be. Some set of features considered together might predict the label with high accuracy, yet taken individually they aren’t very predictive.\n",
    "\n",
    "### Other possible approaches\n",
    "\n",
    "The correlation coefficient of the label against each feature can be used to measure importance. This is very fast, although it only measures the simple relationship of what happens to one variable when the other increases.\n",
    "\n",
    "Principal Component Analysis can be useful to eliminate redundant features. Although this involves transforming the features into components, which is difficult to translate back to the importance of a single feature.\n",
    "\n",
    "For each feature, one can train a model without that feature. Eliminate the feature which gave the lowest (or highest) score on the test data. Repeat this until there is only one feature left. This would address the weakness of the selected approach by capturing the importance of features in combination. Although it is a fairly slow approach, requiring a quadratic number of models to be trained. Depending on the type of model and hyperparameters used, training each individual model may also take some time and potentially require some parameter tweaking to get right. I quickly tried this approach, although it was heavily affected by noise, making the end result somewhat random and not suitable to draw conclusions from.\n",
    "\n",
    "One can also train a model on every subset of features and judge the importance of a feature based on the performance of the models with and without that feature. Compared to the above, this would be a good way to avoid potentially early on eliminating single features which are highly correlated with the output, but is less predictive than a subset of other features. However, this would be extremely slow: an exponential number of models will need to be trained.\n",
    "\n",
    "Other models could also have been used instead of support vector machines. Given the size of the dataset, some approaches typically requiring large datasets wouldn’t be promising. Neural networks is one example of this, although reducing the number of neurons, hidden layers and iterations would allow it to work for smaller datasets. This may require a lot more tweaking to get right compared to SVMs. There are other approaches that work with small datasets: Logistic regression only captures the relationship where there is some cutoff after which the label is true. Decision trees are more suited to datasets containing categorical or discrete data. Naive Bayes assumes independence between features and isn’t particularly well-suited to continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ca6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Individual importance 0:       [6, 8, 4, 2, 0, 3, 9, 5, 1, 7]\n",
      "     Individual importance 1:       [6, 2, 8, 0, 4, 3, 5, 9, 7, 1]\n",
      "     Individual importance 2:       [6, 8, 4, 0, 2, 3, 9, 5, 7, 1]\n",
      "     Individual importance 3:       [6, 8, 4, 2, 0, 9, 3, 7, 1, 5]\n",
      "Individual percentages (mean): [0.97, 0.88, 0.84, 0.80, 0.79, 0.72, 0.66, 0.56, 0.54, 0.48]\n",
      "Individual percentages (std):  [0.02, 0.02, 0.01, 0.06, 0.03, 0.01, 0.05, 0.05, 0.04, 0.03]\n",
      "\n",
      "Final ranking:                 [6, 8, 4, 2, 0, 3, 9, 5, 7, 1]\n",
      "\n",
      "Other measures:\n",
      "Combined importance:           [0, 6, 8, 4, 2, 1, 5, 3, 9, 7]\n",
      "Combined invert importance:    [6, 7, 9, 4, 1, 5, 2, 3, 8, 0]\n",
      "Correlation:                   [8, 4, 0, 3, 1, 5, 7, 9, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "\n",
    "from numpy import mean, std\n",
    "from pandas import read_csv\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def split_train_and_test(data, train_frac):\n",
    "    \"\"\" Split data into training and test, with the training size equal to the\n",
    "        fraction provided\n",
    "    \"\"\"\n",
    "    pos = data.loc[data['class_label'] == 1.0]\n",
    "    neg = data.loc[data['class_label'] == 0.0]\n",
    "    shuffled_pos = pos.sample(frac=1)\n",
    "    shuffled_neg = neg.sample(frac=1)\n",
    "    pos_offset = int(len(pos)*train_frac)\n",
    "    neg_offset = int(len(neg)*train_frac)\n",
    "    train = shuffled_pos[:pos_offset].append(shuffled_neg[:neg_offset])\n",
    "    test = shuffled_pos[pos_offset:].append(shuffled_neg[neg_offset:])\n",
    "    return train, test\n",
    "\n",
    "def extract_section(dataframe, index, count):\n",
    "    \"\"\" Extracts section `index` of `count` sections from the dataframe. Returns\n",
    "        (section, rest)\n",
    "    \"\"\"\n",
    "    offset = int(len(dataframe) / count)\n",
    "    start = index * offset\n",
    "    end = (index + 1) * offset\n",
    "    return dataframe[start:end], dataframe[:start].append(dataframe[end:])\n",
    "\n",
    "IndexValue = namedtuple('IndexedValue', 'index value')\n",
    "\n",
    "def correlation_importance(data):\n",
    "    \"\"\" Returns the features sorted by the Pearson correlation coefficient from\n",
    "        most to least important\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    for i in range(10):\n",
    "        corr, _ = pearsonr(data['class_label'], data[f'sensor{i}'])\n",
    "        correlations.append(IndexValue(i, corr))\n",
    "    return [x.index for x in sorted(correlations, key=lambda x: abs(x.value),\n",
    "                                    reverse=True)]\n",
    "\n",
    "def combined_importance(data, train_frac, invert):\n",
    "    \"\"\" For each feature, train a model without that feature. Eliminate the\n",
    "        feature which gave the lowest score on test data (or highest, if invert\n",
    "        is set). Repeat until there is only one feature left. Returns the list\n",
    "        of features removed, from most to least important\n",
    "    \"\"\"\n",
    "    train, test = split_train_and_test(data, train_frac=train_frac)\n",
    "    columns = [IndexValue(i, f'sensor{i}') for i in range(10)]\n",
    "    removed = []\n",
    "    while len(columns) > 1:\n",
    "        best, bcol = -1 if invert else 2, None\n",
    "        for col in columns:\n",
    "            model = SVC(gamma='scale')\n",
    "            model.fit(train[[c.value for c in columns if c != col]], train['class_label'])\n",
    "            score = model.score(test[[c.value for c in columns if c != col]], test['class_label'])\n",
    "            if (invert and score > best) or (not invert and score < best):\n",
    "                best = score\n",
    "                bcol = col\n",
    "        removed.append(bcol.index)\n",
    "        columns = [c for c in columns if c != bcol]\n",
    "    removed.append(columns[0].index)\n",
    "    if invert:\n",
    "        removed.reverse()\n",
    "    return removed\n",
    "\n",
    "def individual_importance(data, cv_sections):\n",
    "    \"\"\" Trains a model for each individual feature. The data is split into\n",
    "        `cv_sections`, and the training is run multiple times with each section\n",
    "        as a test set, with the rest used for the train set. The average score\n",
    "        on the test sets is then used as the importance of a feature. Returns a\n",
    "        iterable of (feature, [scores]), from most to least important\n",
    "    \"\"\"\n",
    "    shuffled_pos = data.loc[data['class_label'] == 1.0].sample(frac=1)\n",
    "    shuffled_neg = data.loc[data['class_label'] == 0.0].sample(frac=1)\n",
    "    combined_scores = defaultdict(list)\n",
    "    for test_i in range(cv_sections):\n",
    "        test_pos, train_pos = extract_section(shuffled_pos, test_i, cv_sections)\n",
    "        test_neg, train_neg = extract_section(shuffled_neg, test_i, cv_sections)\n",
    "        train = train_pos.append(train_neg)\n",
    "        test = test_pos.append(test_neg)\n",
    "        scores = []\n",
    "        for i in range(10):\n",
    "            model = SVC(gamma='auto')\n",
    "            model.fit(train[[f'sensor{i}']], train['class_label'])\n",
    "            score = model.score(test[[f'sensor{i}']], test['class_label'])\n",
    "            scores.append(IndexValue(i, score))\n",
    "        scores.sort(key=lambda iv: iv.value, reverse=True)\n",
    "        log(f\"Individual importance {test_i}:\", [iv.index for iv in scores],\n",
    "            prefix=\"    \")\n",
    "        for score_iv in scores:\n",
    "            combined_scores[score_iv.index].append(score_iv.value)\n",
    "    return sorted(combined_scores.items(), key=lambda kv: sum(kv[1]),\n",
    "                  reverse=True)\n",
    "\n",
    "def log(key, value, key_width=30, prefix=\"\"):\n",
    "    \"\"\" Print the given key and value, with spaces to the right of key up to\n",
    "        `key_width`\n",
    "    \"\"\"\n",
    "    if prefix:\n",
    "        print(prefix, key.ljust(key_width), value)\n",
    "    else:\n",
    "        print(key.ljust(key_width), value)\n",
    "\n",
    "data = read_csv('data/sensor-data.csv')\n",
    "data.loc[data['class_label'] == -1, 'class_label'] = 0\n",
    "\n",
    "combined_scores = individual_importance(data, cv_sections=4)\n",
    "log(\"Individual percentages (mean):\",\n",
    "    \"[%s]\" % \", \".join(\"%2.2f\" % mean(x[1]) for x in combined_scores))\n",
    "log(\"Individual percentages (std):\",\n",
    "    \"[%s]\" % \", \".join(\"%2.2f\" % std(x[1]) for x in combined_scores))\n",
    "print()\n",
    "log(\"Final ranking:\", [x[0] for x in combined_scores])\n",
    "with open('ranking.txt', 'w') as file:\n",
    "    file.write(\"\\n\".join(f\"sensor{score[0]}\" for score in combined_scores))\n",
    "\n",
    "print()\n",
    "print(\"Other measures:\")\n",
    "log(\"Combined importance:\", combined_importance(data, 0.75, invert=False))\n",
    "log(\"Combined invert importance:\",\n",
    "    combined_importance(data, 0.75, invert=True))\n",
    "log(\"Correlation:\", correlation_importance(data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartsteel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
